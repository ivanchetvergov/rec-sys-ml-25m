1)
смотри вот структура датасета
[2 JSON файла отвечающие за полноту и метаданные датасетов]

наша задача сейчас написать препроцессинг.

1. считываем данные из разных таблиц
2. соединияем все в одно полотно
3. делаем feature engenireeng
4. храним все данные в общем feature store

оформляем все эти вещи как самостоятельные классы пишем краткий понятный и поддерживаемый код и начинаем вести makefile для автоматизации
не перегружай его излишним ф0оналом добавь туда просто этап препроцессинга
и пайтон я использую глобальный из user/ivan/myvenv

2) давай реализуем модель popularity-based с мониторингом ml-flow, которая будет читать лишь часть данных вместо всего хранилища для более простого тестирования и работы модели

3) давай начнем с малого, давай реализуем базовую страницу главную где будут наши самые популярные фильмы

пиши код как и ранее в виде классов по всем принципам, самое главное не усложняй код, там где это не нужно

4) напиши несколько документаций к каждому слою программы, должна быть общая директория docs/ там архитектура, веб с ручками, бекенд, документ по API и тд
