1)
смотри вот структура датасета
[2 JSON файла отвечающие за полноту и метаданные датасетов]

наша задача сейчас написать препроцессинг.

1) считываем данные из разных таблиц
2) соединияем все в одно полотно
3) делаем feature engenireeng
4) храним все данные в общем feature store

оформляем все эти вещи как самостоятельные классы пишем краткий понятный и поддерживаемый клод и начинаем вести makefile для автоматизации
не перегружай его излишним ф0оналом добавь туда просто этап препроцессинга
и пайтон я использую глобальный из user/ivan/myvenv

2) давай реализуем модель popularity-based с мониторингом ml-flow, которая будет читать лишь часть данных вместо всего хранилища для более простого тестирования и работы модели
